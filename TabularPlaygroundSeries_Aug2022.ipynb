{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:40.713852Z",
     "iopub.status.busy": "2022-08-31T16:06:40.713452Z",
     "iopub.status.idle": "2022-08-31T16:06:40.724541Z",
     "shell.execute_reply": "2022-08-31T16:06:40.723300Z",
     "shell.execute_reply.started": "2022-08-31T16:06:40.713810Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:41.079712Z",
     "iopub.status.busy": "2022-08-31T16:06:41.077046Z",
     "iopub.status.idle": "2022-08-31T16:06:41.209125Z",
     "shell.execute_reply": "2022-08-31T16:06:41.208170Z",
     "shell.execute_reply.started": "2022-08-31T16:06:41.079575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26565</th>\n",
       "      <td>26565</td>\n",
       "      <td>E</td>\n",
       "      <td>158.95</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.177</td>\n",
       "      <td>17.942</td>\n",
       "      <td>10.112</td>\n",
       "      <td>15.795</td>\n",
       "      <td>18.572</td>\n",
       "      <td>16.144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26566</th>\n",
       "      <td>26566</td>\n",
       "      <td>E</td>\n",
       "      <td>146.02</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.242</td>\n",
       "      <td>14.179</td>\n",
       "      <td>20.564</td>\n",
       "      <td>10.234</td>\n",
       "      <td>14.450</td>\n",
       "      <td>14.322</td>\n",
       "      <td>13.146</td>\n",
       "      <td>16.471</td>\n",
       "      <td>853.924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26567</th>\n",
       "      <td>26567</td>\n",
       "      <td>E</td>\n",
       "      <td>115.62</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11.407</td>\n",
       "      <td>16.437</td>\n",
       "      <td>17.476</td>\n",
       "      <td>8.668</td>\n",
       "      <td>15.069</td>\n",
       "      <td>16.599</td>\n",
       "      <td>15.590</td>\n",
       "      <td>14.065</td>\n",
       "      <td>750.364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26568</th>\n",
       "      <td>26568</td>\n",
       "      <td>E</td>\n",
       "      <td>106.38</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11.392</td>\n",
       "      <td>17.064</td>\n",
       "      <td>17.814</td>\n",
       "      <td>14.928</td>\n",
       "      <td>16.273</td>\n",
       "      <td>15.485</td>\n",
       "      <td>13.624</td>\n",
       "      <td>12.865</td>\n",
       "      <td>730.156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26569</th>\n",
       "      <td>26569</td>\n",
       "      <td>E</td>\n",
       "      <td>131.20</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.611</td>\n",
       "      <td>15.603</td>\n",
       "      <td>19.703</td>\n",
       "      <td>11.006</td>\n",
       "      <td>15.875</td>\n",
       "      <td>13.366</td>\n",
       "      <td>16.527</td>\n",
       "      <td>17.890</td>\n",
       "      <td>602.354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26570 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id product_code  loading attribute_0 attribute_1  attribute_2  \\\n",
       "0          0            A    80.10  material_7  material_8            9   \n",
       "1          1            A    84.89  material_7  material_8            9   \n",
       "2          2            A    82.43  material_7  material_8            9   \n",
       "3          3            A   101.07  material_7  material_8            9   \n",
       "4          4            A   188.06  material_7  material_8            9   \n",
       "...      ...          ...      ...         ...         ...          ...   \n",
       "26565  26565            E   158.95  material_7  material_6            6   \n",
       "26566  26566            E   146.02  material_7  material_6            6   \n",
       "26567  26567            E   115.62  material_7  material_6            6   \n",
       "26568  26568            E   106.38  material_7  material_6            6   \n",
       "26569  26569            E   131.20  material_7  material_6            6   \n",
       "\n",
       "       attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n",
       "0                5              7              8              4  ...   \n",
       "1                5             14              3              3  ...   \n",
       "2                5             12              1              5  ...   \n",
       "3                5             13              2              6  ...   \n",
       "4                5              9              2              8  ...   \n",
       "...            ...            ...            ...            ...  ...   \n",
       "26565            9              6             16              4  ...   \n",
       "26566            9             10             12              8  ...   \n",
       "26567            9              1             10              1  ...   \n",
       "26568            9              2              9              4  ...   \n",
       "26569            9              6             19              1  ...   \n",
       "\n",
       "       measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
       "0             10.672          15.859          17.594          15.193   \n",
       "1             12.448          17.947          17.915          11.755   \n",
       "2             12.715          15.607             NaN          13.798   \n",
       "3             12.471          16.346          18.377          10.020   \n",
       "4             10.337          17.082          19.932          12.428   \n",
       "...              ...             ...             ...             ...   \n",
       "26565            NaN          12.177          17.942          10.112   \n",
       "26566         11.242          14.179          20.564          10.234   \n",
       "26567         11.407          16.437          17.476           8.668   \n",
       "26568         11.392          17.064          17.814          14.928   \n",
       "26569         10.611          15.603          19.703          11.006   \n",
       "\n",
       "       measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
       "0              15.029             NaN          13.034          14.684   \n",
       "1              14.732          15.425          14.395          15.631   \n",
       "2              16.711          18.631          14.094          17.946   \n",
       "3              15.250          15.562          16.154          17.172   \n",
       "4              16.182          12.760          13.153          16.412   \n",
       "...               ...             ...             ...             ...   \n",
       "26565          15.795          18.572          16.144             NaN   \n",
       "26566          14.450          14.322          13.146          16.471   \n",
       "26567          15.069          16.599          15.590          14.065   \n",
       "26568          16.273          15.485          13.624          12.865   \n",
       "26569          15.875          13.366          16.527          17.890   \n",
       "\n",
       "       measurement_17  failure  \n",
       "0             764.100        0  \n",
       "1             682.057        0  \n",
       "2             663.376        0  \n",
       "3             826.282        0  \n",
       "4             579.885        0  \n",
       "...               ...      ...  \n",
       "26565         729.131        0  \n",
       "26566         853.924        0  \n",
       "26567         750.364        0  \n",
       "26568         730.156        0  \n",
       "26569         602.354        0  \n",
       "\n",
       "[26570 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get train/test dfs\n",
    "\n",
    "train_df = pd.read_csv('train.csv.zip', compression='zip')\n",
    "test_df = pd.read_csv('test.csv.zip', compression='zip')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T10:19:54.324742Z",
     "iopub.status.busy": "2022-08-31T10:19:54.324170Z",
     "iopub.status.idle": "2022-08-31T10:19:54.369295Z",
     "shell.execute_reply": "2022-08-31T10:19:54.368250Z",
     "shell.execute_reply.started": "2022-08-31T10:19:54.324695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>F</td>\n",
       "      <td>119.57</td>\n",
       "      <td>material_5</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>18.654</td>\n",
       "      <td>10.802</td>\n",
       "      <td>15.909</td>\n",
       "      <td>18.070</td>\n",
       "      <td>13.772</td>\n",
       "      <td>13.659</td>\n",
       "      <td>16.825</td>\n",
       "      <td>13.742</td>\n",
       "      <td>17.710</td>\n",
       "      <td>634.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>F</td>\n",
       "      <td>113.51</td>\n",
       "      <td>material_5</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.368</td>\n",
       "      <td>12.032</td>\n",
       "      <td>13.998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.473</td>\n",
       "      <td>17.468</td>\n",
       "      <td>16.708</td>\n",
       "      <td>14.776</td>\n",
       "      <td>14.102</td>\n",
       "      <td>537.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>F</td>\n",
       "      <td>112.16</td>\n",
       "      <td>material_5</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.774</td>\n",
       "      <td>11.743</td>\n",
       "      <td>17.046</td>\n",
       "      <td>18.086</td>\n",
       "      <td>10.907</td>\n",
       "      <td>13.363</td>\n",
       "      <td>15.737</td>\n",
       "      <td>17.065</td>\n",
       "      <td>16.021</td>\n",
       "      <td>658.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>F</td>\n",
       "      <td>112.72</td>\n",
       "      <td>material_5</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>18.948</td>\n",
       "      <td>11.790</td>\n",
       "      <td>18.165</td>\n",
       "      <td>16.163</td>\n",
       "      <td>10.933</td>\n",
       "      <td>15.501</td>\n",
       "      <td>15.667</td>\n",
       "      <td>12.620</td>\n",
       "      <td>16.111</td>\n",
       "      <td>594.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>F</td>\n",
       "      <td>208.00</td>\n",
       "      <td>material_5</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>19.141</td>\n",
       "      <td>12.370</td>\n",
       "      <td>14.578</td>\n",
       "      <td>17.849</td>\n",
       "      <td>11.941</td>\n",
       "      <td>16.070</td>\n",
       "      <td>16.183</td>\n",
       "      <td>13.324</td>\n",
       "      <td>17.150</td>\n",
       "      <td>801.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20770</th>\n",
       "      <td>47340</td>\n",
       "      <td>I</td>\n",
       "      <td>144.74</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>18.573</td>\n",
       "      <td>11.691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.771</td>\n",
       "      <td>11.562</td>\n",
       "      <td>17.246</td>\n",
       "      <td>15.131</td>\n",
       "      <td>15.209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>696.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20771</th>\n",
       "      <td>47341</td>\n",
       "      <td>I</td>\n",
       "      <td>74.53</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>17.917</td>\n",
       "      <td>10.980</td>\n",
       "      <td>16.027</td>\n",
       "      <td>15.694</td>\n",
       "      <td>13.564</td>\n",
       "      <td>15.494</td>\n",
       "      <td>15.296</td>\n",
       "      <td>13.812</td>\n",
       "      <td>16.501</td>\n",
       "      <td>613.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20772</th>\n",
       "      <td>47342</td>\n",
       "      <td>I</td>\n",
       "      <td>67.73</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.630</td>\n",
       "      <td>10.436</td>\n",
       "      <td>16.137</td>\n",
       "      <td>20.612</td>\n",
       "      <td>11.134</td>\n",
       "      <td>16.519</td>\n",
       "      <td>15.525</td>\n",
       "      <td>14.175</td>\n",
       "      <td>17.728</td>\n",
       "      <td>783.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20773</th>\n",
       "      <td>47343</td>\n",
       "      <td>I</td>\n",
       "      <td>126.15</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>19.575</td>\n",
       "      <td>12.672</td>\n",
       "      <td>15.422</td>\n",
       "      <td>19.496</td>\n",
       "      <td>9.319</td>\n",
       "      <td>15.817</td>\n",
       "      <td>17.403</td>\n",
       "      <td>16.437</td>\n",
       "      <td>15.179</td>\n",
       "      <td>745.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20774</th>\n",
       "      <td>47344</td>\n",
       "      <td>I</td>\n",
       "      <td>85.97</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>19.253</td>\n",
       "      <td>9.977</td>\n",
       "      <td>17.270</td>\n",
       "      <td>17.924</td>\n",
       "      <td>13.726</td>\n",
       "      <td>14.605</td>\n",
       "      <td>17.460</td>\n",
       "      <td>16.261</td>\n",
       "      <td>16.482</td>\n",
       "      <td>647.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20775 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id product_code  loading attribute_0 attribute_1  attribute_2  \\\n",
       "0      26570            F   119.57  material_5  material_6            6   \n",
       "1      26571            F   113.51  material_5  material_6            6   \n",
       "2      26572            F   112.16  material_5  material_6            6   \n",
       "3      26573            F   112.72  material_5  material_6            6   \n",
       "4      26574            F   208.00  material_5  material_6            6   \n",
       "...      ...          ...      ...         ...         ...          ...   \n",
       "20770  47340            I   144.74  material_7  material_5            9   \n",
       "20771  47341            I    74.53  material_7  material_5            9   \n",
       "20772  47342            I    67.73  material_7  material_5            9   \n",
       "20773  47343            I   126.15  material_7  material_5            9   \n",
       "20774  47344            I    85.97  material_7  material_5            9   \n",
       "\n",
       "       attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n",
       "0                4              6              9              6  ...   \n",
       "1                4             11              8              0  ...   \n",
       "2                4              8             12              4  ...   \n",
       "3                4              8             11             10  ...   \n",
       "4                4             14             16              8  ...   \n",
       "...            ...            ...            ...            ...  ...   \n",
       "20770            5              0              4              9  ...   \n",
       "20771            5              4              8              7  ...   \n",
       "20772            5             10             11              2  ...   \n",
       "20773            5              8             16             11  ...   \n",
       "20774            5              0             11             11  ...   \n",
       "\n",
       "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "0             18.654         10.802          15.909          18.070   \n",
       "1             19.368         12.032          13.998             NaN   \n",
       "2             17.774         11.743          17.046          18.086   \n",
       "3             18.948         11.790          18.165          16.163   \n",
       "4             19.141         12.370          14.578          17.849   \n",
       "...              ...            ...             ...             ...   \n",
       "20770         18.573         11.691             NaN          19.771   \n",
       "20771         17.917         10.980          16.027          15.694   \n",
       "20772         19.630         10.436          16.137          20.612   \n",
       "20773         19.575         12.672          15.422          19.496   \n",
       "20774         19.253          9.977          17.270          17.924   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "0              13.772          13.659          16.825          13.742   \n",
       "1              12.473          17.468          16.708          14.776   \n",
       "2              10.907          13.363          15.737          17.065   \n",
       "3              10.933          15.501          15.667          12.620   \n",
       "4              11.941          16.070          16.183          13.324   \n",
       "...               ...             ...             ...             ...   \n",
       "20770          11.562          17.246          15.131          15.209   \n",
       "20771          13.564          15.494          15.296          13.812   \n",
       "20772          11.134          16.519          15.525          14.175   \n",
       "20773           9.319          15.817          17.403          16.437   \n",
       "20774          13.726          14.605          17.460          16.261   \n",
       "\n",
       "       measurement_16  measurement_17  \n",
       "0              17.710         634.612  \n",
       "1              14.102         537.037  \n",
       "2              16.021         658.995  \n",
       "3              16.111         594.301  \n",
       "4              17.150         801.044  \n",
       "...               ...             ...  \n",
       "20770             NaN         696.466  \n",
       "20771          16.501         613.249  \n",
       "20772          17.728         783.349  \n",
       "20773          15.179         745.210  \n",
       "20774          16.482         647.980  \n",
       "\n",
       "[20775 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T10:19:01.403787Z",
     "iopub.status.busy": "2022-08-31T10:19:01.403343Z",
     "iopub.status.idle": "2022-08-31T10:19:01.512006Z",
     "shell.execute_reply": "2022-08-31T10:19:01.511153Z",
     "shell.execute_reply.started": "2022-08-31T10:19:01.403749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26570.000000</td>\n",
       "      <td>26320.000000</td>\n",
       "      <td>26570.000000</td>\n",
       "      <td>26570.000000</td>\n",
       "      <td>26570.000000</td>\n",
       "      <td>26570.000000</td>\n",
       "      <td>26570.000000</td>\n",
       "      <td>26189.000000</td>\n",
       "      <td>26032.000000</td>\n",
       "      <td>25894.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25343.000000</td>\n",
       "      <td>25270.000000</td>\n",
       "      <td>25102.000000</td>\n",
       "      <td>24969.000000</td>\n",
       "      <td>24796.000000</td>\n",
       "      <td>24696.000000</td>\n",
       "      <td>24561.000000</td>\n",
       "      <td>24460.000000</td>\n",
       "      <td>24286.000000</td>\n",
       "      <td>26570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13284.500000</td>\n",
       "      <td>127.826233</td>\n",
       "      <td>6.754046</td>\n",
       "      <td>7.240459</td>\n",
       "      <td>7.415883</td>\n",
       "      <td>8.232518</td>\n",
       "      <td>6.256568</td>\n",
       "      <td>17.791528</td>\n",
       "      <td>11.731988</td>\n",
       "      <td>17.127804</td>\n",
       "      <td>...</td>\n",
       "      <td>11.430725</td>\n",
       "      <td>16.117711</td>\n",
       "      <td>19.172085</td>\n",
       "      <td>11.702464</td>\n",
       "      <td>15.652904</td>\n",
       "      <td>16.048444</td>\n",
       "      <td>14.995554</td>\n",
       "      <td>16.460727</td>\n",
       "      <td>701.269059</td>\n",
       "      <td>0.212608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7670.242662</td>\n",
       "      <td>39.030020</td>\n",
       "      <td>1.471852</td>\n",
       "      <td>1.456493</td>\n",
       "      <td>4.116690</td>\n",
       "      <td>4.199401</td>\n",
       "      <td>3.309109</td>\n",
       "      <td>1.001200</td>\n",
       "      <td>0.996085</td>\n",
       "      <td>0.996414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999137</td>\n",
       "      <td>1.405978</td>\n",
       "      <td>1.520785</td>\n",
       "      <td>1.488838</td>\n",
       "      <td>1.155247</td>\n",
       "      <td>1.491923</td>\n",
       "      <td>1.549226</td>\n",
       "      <td>1.708935</td>\n",
       "      <td>123.304161</td>\n",
       "      <td>0.409160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.160000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.968000</td>\n",
       "      <td>8.008000</td>\n",
       "      <td>12.073000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.537000</td>\n",
       "      <td>9.323000</td>\n",
       "      <td>12.461000</td>\n",
       "      <td>5.167000</td>\n",
       "      <td>10.890000</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>9.104000</td>\n",
       "      <td>9.701000</td>\n",
       "      <td>196.787000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6642.250000</td>\n",
       "      <td>99.987500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.117000</td>\n",
       "      <td>11.051000</td>\n",
       "      <td>16.443000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.757000</td>\n",
       "      <td>15.209000</td>\n",
       "      <td>18.170000</td>\n",
       "      <td>10.703000</td>\n",
       "      <td>14.890000</td>\n",
       "      <td>15.057000</td>\n",
       "      <td>13.957000</td>\n",
       "      <td>15.268000</td>\n",
       "      <td>618.961500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13284.500000</td>\n",
       "      <td>122.390000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.787000</td>\n",
       "      <td>11.733000</td>\n",
       "      <td>17.132000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>16.127000</td>\n",
       "      <td>19.211500</td>\n",
       "      <td>11.717000</td>\n",
       "      <td>15.628500</td>\n",
       "      <td>16.040000</td>\n",
       "      <td>14.969000</td>\n",
       "      <td>16.436000</td>\n",
       "      <td>701.024500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19926.750000</td>\n",
       "      <td>149.152500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.469000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>17.805000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.102000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>20.207000</td>\n",
       "      <td>12.709000</td>\n",
       "      <td>16.374000</td>\n",
       "      <td>17.082000</td>\n",
       "      <td>16.018000</td>\n",
       "      <td>17.628000</td>\n",
       "      <td>784.090250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26569.000000</td>\n",
       "      <td>385.860000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>21.499000</td>\n",
       "      <td>16.484000</td>\n",
       "      <td>21.425000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.412000</td>\n",
       "      <td>22.479000</td>\n",
       "      <td>25.640000</td>\n",
       "      <td>17.663000</td>\n",
       "      <td>22.713000</td>\n",
       "      <td>22.303000</td>\n",
       "      <td>21.626000</td>\n",
       "      <td>24.094000</td>\n",
       "      <td>1312.794000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       loading   attribute_2   attribute_3  measurement_0  \\\n",
       "count  26570.000000  26320.000000  26570.000000  26570.000000   26570.000000   \n",
       "mean   13284.500000    127.826233      6.754046      7.240459       7.415883   \n",
       "std     7670.242662     39.030020      1.471852      1.456493       4.116690   \n",
       "min        0.000000     33.160000      5.000000      5.000000       0.000000   \n",
       "25%     6642.250000     99.987500      6.000000      6.000000       4.000000   \n",
       "50%    13284.500000    122.390000      6.000000      8.000000       7.000000   \n",
       "75%    19926.750000    149.152500      8.000000      8.000000      10.000000   \n",
       "max    26569.000000    385.860000      9.000000      9.000000      29.000000   \n",
       "\n",
       "       measurement_1  measurement_2  measurement_3  measurement_4  \\\n",
       "count   26570.000000   26570.000000   26189.000000   26032.000000   \n",
       "mean        8.232518       6.256568      17.791528      11.731988   \n",
       "std         4.199401       3.309109       1.001200       0.996085   \n",
       "min         0.000000       0.000000      13.968000       8.008000   \n",
       "25%         5.000000       4.000000      17.117000      11.051000   \n",
       "50%         8.000000       6.000000      17.787000      11.733000   \n",
       "75%        11.000000       8.000000      18.469000      12.410000   \n",
       "max        29.000000      24.000000      21.499000      16.484000   \n",
       "\n",
       "       measurement_5  ...  measurement_9  measurement_10  measurement_11  \\\n",
       "count   25894.000000  ...   25343.000000    25270.000000    25102.000000   \n",
       "mean       17.127804  ...      11.430725       16.117711       19.172085   \n",
       "std         0.996414  ...       0.999137        1.405978        1.520785   \n",
       "min        12.073000  ...       7.537000        9.323000       12.461000   \n",
       "25%        16.443000  ...      10.757000       15.209000       18.170000   \n",
       "50%        17.132000  ...      11.430000       16.127000       19.211500   \n",
       "75%        17.805000  ...      12.102000       17.025000       20.207000   \n",
       "max        21.425000  ...      15.412000       22.479000       25.640000   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "count    24969.000000    24796.000000    24696.000000    24561.000000   \n",
       "mean        11.702464       15.652904       16.048444       14.995554   \n",
       "std          1.488838        1.155247        1.491923        1.549226   \n",
       "min          5.167000       10.890000        9.140000        9.104000   \n",
       "25%         10.703000       14.890000       15.057000       13.957000   \n",
       "50%         11.717000       15.628500       16.040000       14.969000   \n",
       "75%         12.709000       16.374000       17.082000       16.018000   \n",
       "max         17.663000       22.713000       22.303000       21.626000   \n",
       "\n",
       "       measurement_16  measurement_17       failure  \n",
       "count    24460.000000    24286.000000  26570.000000  \n",
       "mean        16.460727      701.269059      0.212608  \n",
       "std          1.708935      123.304161      0.409160  \n",
       "min          9.701000      196.787000      0.000000  \n",
       "25%         15.268000      618.961500      0.000000  \n",
       "50%         16.436000      701.024500      0.000000  \n",
       "75%         17.628000      784.090250      0.000000  \n",
       "max         24.094000     1312.794000      1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:47.814975Z",
     "iopub.status.busy": "2022-08-31T16:06:47.814572Z",
     "iopub.status.idle": "2022-08-31T16:06:47.834751Z",
     "shell.execute_reply": "2022-08-31T16:06:47.833579Z",
     "shell.execute_reply.started": "2022-08-31T16:06:47.814950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train set:\n",
      "product_code ['A' 'B' 'C' 'D' 'E']\n",
      "attribute_0 ['material_7' 'material_5']\n",
      "attribute_1 ['material_8' 'material_5' 'material_6']\n",
      "\n",
      "For test set:\n",
      "product_code ['F' 'G' 'H' 'I']\n",
      "attribute_0 ['material_5' 'material_7']\n",
      "attribute_1 ['material_6' 'material_7' 'material_5']\n"
     ]
    }
   ],
   "source": [
    "# Explore unique entries in categorical columns:\n",
    "\n",
    "cat_cols = ['product_code','attribute_0','attribute_1']\n",
    "\n",
    "# For train set:\n",
    "print('For train set:')\n",
    "for col in cat_cols:\n",
    "    print(col, train_df.loc[:,col].unique())\n",
    "\n",
    "print('\\nFor test set:')\n",
    "# For test set:\n",
    "for col in cat_cols:\n",
    "    print(col, test_df.loc[:,col].unique())\n",
    "    \n",
    "# Notice that 'product_code' unique entries among train and test dataset are completely different:\n",
    "# I remove this columnn\n",
    "train_df = train_df.drop('product_code', axis = 1)\n",
    "test_df = test_df.drop('product_code', axis = 1)\n",
    "cat_cols.remove('product_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:50.859869Z",
     "iopub.status.busy": "2022-08-31T16:06:50.859545Z",
     "iopub.status.idle": "2022-08-31T16:06:50.874308Z",
     "shell.execute_reply": "2022-08-31T16:06:50.873374Z",
     "shell.execute_reply.started": "2022-08-31T16:06:50.859845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train set:\n",
      "material_8    10865\n",
      "material_5    10362\n",
      "material_6     5343\n",
      "Name: attribute_1, dtype: int64\n",
      "\n",
      "For test set:\n",
      "material_6    10529\n",
      "material_5     5228\n",
      "material_7     5018\n",
      "Name: attribute_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train_df, 'attribute_1' column has one entry different than test_df (material_8 vs material_7):\n",
    "\n",
    "# Let's see how many material_8 and material_7 entries there are.\n",
    "# If they are few --> drop them\n",
    "\n",
    "print('For train set:')\n",
    "print(train_df['attribute_1'].value_counts())\n",
    "print('\\nFor test set:')\n",
    "print(test_df['attribute_1'].value_counts())\n",
    "\n",
    "# Rows are too many to be waisted.\n",
    "# I will drop attribute_1 column too:\n",
    "train_df = train_df.drop('attribute_1', axis = 1)\n",
    "test_df = test_df.drop('attribute_1', axis = 1)\n",
    "cat_cols.remove('attribute_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:53.715061Z",
     "iopub.status.busy": "2022-08-31T16:06:53.714180Z",
     "iopub.status.idle": "2022-08-31T16:06:53.736004Z",
     "shell.execute_reply": "2022-08-31T16:06:53.735110Z",
     "shell.execute_reply.started": "2022-08-31T16:06:53.715025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train_df:\n",
      "id 0\n",
      "loading 250\n",
      "attribute_0 0\n",
      "attribute_2 0\n",
      "attribute_3 0\n",
      "measurement_0 0\n",
      "measurement_1 0\n",
      "measurement_2 0\n",
      "measurement_3 381\n",
      "measurement_4 538\n",
      "measurement_5 676\n",
      "measurement_6 796\n",
      "measurement_7 937\n",
      "measurement_8 1048\n",
      "measurement_9 1227\n",
      "measurement_10 1300\n",
      "measurement_11 1468\n",
      "measurement_12 1601\n",
      "measurement_13 1774\n",
      "measurement_14 1874\n",
      "measurement_15 2009\n",
      "measurement_16 2110\n",
      "measurement_17 2284\n",
      "failure 0\n",
      "\n",
      "for test_df:\n",
      "id 0\n",
      "loading 223\n",
      "attribute_0 0\n",
      "attribute_2 0\n",
      "attribute_3 0\n",
      "measurement_0 0\n",
      "measurement_1 0\n",
      "measurement_2 0\n",
      "measurement_3 329\n",
      "measurement_4 409\n",
      "measurement_5 508\n",
      "measurement_6 624\n",
      "measurement_7 720\n",
      "measurement_8 846\n",
      "measurement_9 904\n",
      "measurement_10 1067\n",
      "measurement_11 1136\n",
      "measurement_12 1240\n",
      "measurement_13 1303\n",
      "measurement_14 1440\n",
      "measurement_15 1542\n",
      "measurement_16 1678\n",
      "measurement_17 1740\n"
     ]
    }
   ],
   "source": [
    "#Explore amount of nans among all columns:\n",
    "\n",
    "print('for train_df:')\n",
    "col_nans_train_df = []\n",
    "for col in train_df.columns:\n",
    "    N_nan = train_df[col].isnull().sum()\n",
    "    col_nans_train_df.append(col)\n",
    "    print(col, N_nan)\n",
    "\n",
    "print('\\nfor test_df:')\n",
    "col_nans_test_df = []\n",
    "for col in test_df.columns:\n",
    "    N_nan = test_df[col].isnull().sum()\n",
    "    col_nans_test_df.append(col)\n",
    "    print(col, N_nan)\n",
    "    \n",
    "# Actions over Nans entries will be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:58.235195Z",
     "iopub.status.busy": "2022-08-31T16:06:58.234903Z",
     "iopub.status.idle": "2022-08-31T16:06:58.283235Z",
     "shell.execute_reply": "2022-08-31T16:06:58.282546Z",
     "shell.execute_reply.started": "2022-08-31T16:06:58.235173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get rid of the Nans:\n",
    "\n",
    "# Categorical columns (they all have Nans):\n",
    "train_df.loc[:,cat_cols] = train_df.loc[:,cat_cols].fillna(train_df.loc[:,cat_cols].mode().iloc[0])\n",
    "test_df.loc[:,cat_cols] = test_df.loc[:,cat_cols].fillna(test_df.loc[:,cat_cols].mode().iloc[0])\n",
    "    \n",
    "# Numerical columns with nans (I choose substitution with mean value):\n",
    "for CC in cat_cols:\n",
    "        col_nans_train_df.remove(CC)\n",
    "        col_nans_test_df.remove(CC)\n",
    "train_df.loc[:,col_nans_train_df] = train_df.loc[:,col_nans_train_df].\\\n",
    "                                    fillna(train_df.loc[:,col_nans_train_df].mean())\n",
    "test_df.loc[:,col_nans_test_df] = test_df.loc[:,col_nans_test_df].\\\n",
    "                                    fillna(test_df.loc[:,col_nans_test_df].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:06:58.543789Z",
     "iopub.status.busy": "2022-08-31T16:06:58.543058Z",
     "iopub.status.idle": "2022-08-31T16:06:58.570037Z",
     "shell.execute_reply": "2022-08-31T16:06:58.569123Z",
     "shell.execute_reply.started": "2022-08-31T16:06:58.543746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Switch categorical entries to numerical (ordinal encoding):\n",
    "# Will test One_Hot encoding later on\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "train_df.loc[:,cat_cols] = ordinal_encoder.fit_transform(train_df.loc[:,cat_cols])\n",
    "test_df.loc[:,cat_cols] = ordinal_encoder.transform(test_df.loc[:,cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T12:11:32.701249Z",
     "iopub.status.busy": "2022-08-31T12:11:32.700782Z",
     "iopub.status.idle": "2022-08-31T12:11:32.723740Z",
     "shell.execute_reply": "2022-08-31T12:11:32.722392Z",
     "shell.execute_reply.started": "2022-08-31T12:11:32.701216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Divide dataframes into X,y:\n",
    "\n",
    "# Full dataframes (for final training for submission)\n",
    "X_cols = train_df.columns.drop('failure')\n",
    "X_train_all = train_df.loc[:,X_cols]\n",
    "y_train_all = train_df.loc[:,'failure']\n",
    "X_test_all = test_df\n",
    "\n",
    "# Get partial train/test sets from train_df to explore different setupd of models/parameters.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring fitting models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a kernelized SVM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T12:51:05.088259Z",
     "iopub.status.busy": "2022-08-31T12:51:05.087845Z",
     "iopub.status.idle": "2022-08-31T13:24:00.216236Z",
     "shell.execute_reply": "2022-08-31T13:24:00.214396Z",
     "shell.execute_reply.started": "2022-08-31T12:51:05.088227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.10  gamma = 0.010 -- > auc = 0.510\n",
      "C = 0.10  gamma = 1.000 -- > auc = 0.500\n",
      "C = 0.10  gamma = 10.000 -- > auc = 0.500\n",
      "C = 1.00  gamma = 0.010 -- > auc = 0.511\n",
      "C = 1.00  gamma = 1.000 -- > auc = 0.500\n",
      "C = 1.00  gamma = 10.000 -- > auc = 0.500\n",
      "C = 10.00  gamma = 0.010 -- > auc = 0.510\n",
      "C = 10.00  gamma = 1.000 -- > auc = 0.500\n",
      "C = 10.00  gamma = 10.000 -- > auc = 0.500\n"
     ]
    }
   ],
   "source": [
    "# Let's tune C and gamma parameters at the same time:\n",
    "\n",
    "C_vals = [0.1, 1.0, 10.]\n",
    "gamma_vals = [0.01, 1.0, 10.0]\n",
    "for C_val in C_vals:\n",
    "    for gamma_val in gamma_vals:\n",
    "        clf = SVC(kernel = 'rbf', C=C_val, gamma=gamma_val)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_clf = clf.decision_function(X_test)\n",
    "        \n",
    "        clf_fpr, clf_tpr, threshold = roc_curve(y_test, y_pred_clf)\n",
    "        auc_clf = auc(clf_fpr, clf_tpr)\n",
    "        print('C = {:.2f}  gamma = {:.3f} -- > auc = {:.3f}'.format(C_val, gamma_val, auc_clf))\n",
    "        \n",
    "# Auc value only sllightly affected by choices of C and gamma parameters. All outcomes are not satisfying (close to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T13:28:58.466028Z",
     "iopub.status.busy": "2022-08-31T13:28:58.465603Z",
     "iopub.status.idle": "2022-08-31T13:47:39.514115Z",
     "shell.execute_reply": "2022-08-31T13:47:39.512950Z",
     "shell.execute_reply.started": "2022-08-31T13:28:58.465973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.10  gamma = 0.010 -- > auc = 0.485\n",
      "C = 0.10  gamma = 1.000 -- > auc = 0.529\n",
      "C = 0.10  gamma = 10.000 -- > auc = 0.537\n",
      "C = 1.00  gamma = 0.010 -- > auc = 0.503\n",
      "C = 1.00  gamma = 1.000 -- > auc = 0.528\n",
      "C = 1.00  gamma = 10.000 -- > auc = 0.537\n",
      "C = 10.00  gamma = 0.010 -- > auc = 0.511\n",
      "C = 10.00  gamma = 1.000 -- > auc = 0.528\n",
      "C = 10.00  gamma = 10.000 -- > auc = 0.525\n"
     ]
    }
   ],
   "source": [
    "# Same as above but with adding MinMax scaler:\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "C_vals = [0.1, 1.0, 10.]\n",
    "gamma_vals = [0.01, 1.0, 10.0]\n",
    "for C_val in C_vals:\n",
    "    for gamma_val in gamma_vals:\n",
    "        clf = SVC(kernel = 'rbf', C=C_val, gamma=gamma_val)\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred_clf = clf.decision_function(X_test_scaled)\n",
    "        \n",
    "        clf_fpr, clf_tpr, threshold = roc_curve(y_test, y_pred_clf)\n",
    "        auc_clf = auc(clf_fpr, clf_tpr)\n",
    "        print('C = {:.2f}  gamma = {:.3f} -- > auc = {:.3f}'.format(C_val, gamma_val, auc_clf))\n",
    "        \n",
    "# Re-scaling improves auc score only slightly.\n",
    "# All outcomes are not satisfying (close to 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try gradient boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T13:56:30.257076Z",
     "iopub.status.busy": "2022-08-31T13:56:30.256680Z",
     "iopub.status.idle": "2022-08-31T14:01:13.005379Z",
     "shell.execute_reply": "2022-08-31T14:01:13.004343Z",
     "shell.execute_reply.started": "2022-08-31T13:56:30.257044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auc score of XGBClassifier with specific parameters values: \n",
      "n_estimators = 350.00  learning_rate = 0.01 --> auc = 0.573\n",
      "n_estimators = 350.00  learning_rate = 0.05 --> auc = 0.559\n",
      "n_estimators = 350.00  learning_rate = 0.10 --> auc = 0.553\n",
      "n_estimators = 350.00  learning_rate = 0.50 --> auc = 0.528\n",
      "n_estimators = 500.00  learning_rate = 0.01 --> auc = 0.570\n",
      "n_estimators = 500.00  learning_rate = 0.05 --> auc = 0.553\n",
      "n_estimators = 500.00  learning_rate = 0.10 --> auc = 0.548\n",
      "n_estimators = 500.00  learning_rate = 0.50 --> auc = 0.530\n",
      "n_estimators = 750.00  learning_rate = 0.01 --> auc = 0.568\n",
      "n_estimators = 750.00  learning_rate = 0.05 --> auc = 0.550\n",
      "n_estimators = 750.00  learning_rate = 0.10 --> auc = 0.543\n",
      "n_estimators = 750.00  learning_rate = 0.50 --> auc = 0.525\n"
     ]
    }
   ],
   "source": [
    "n_est_vals = [350,500,750]\n",
    "learning_rate_vals = [0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "print('\\nAuc score of XGBClassifier with specific parameters values: ')\n",
    "for n_est_val in n_est_vals:\n",
    "    for learning_rate_val in learning_rate_vals:\n",
    "        clf = XGBClassifier(n_estimators=n_est_val, learning_rate = learning_rate_val, eval_metric='logloss')\n",
    "        clf.fit(X_train, y_train, verbose=False)\n",
    "        y_pred_clf = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        clf_fpr, clf_tpr, threshold = roc_curve(y_test, y_pred_clf)\n",
    "        auc_clf = roc_auc_score(y_test, y_pred_clf)\n",
    "        \n",
    "        print('n_estimators = {:.2f}  learning_rate = {:.2f} --> auc = {:.3f}'\\\n",
    "              .format(n_est_val, learning_rate_val, auc_clf))\n",
    "        \n",
    "# Definitely better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try One_Hot encoding instead of Ordinal encoding (with gradient boosting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:07:43.520762Z",
     "iopub.status.busy": "2022-08-31T16:07:43.520418Z",
     "iopub.status.idle": "2022-08-31T16:07:43.677869Z",
     "shell.execute_reply": "2022-08-31T16:07:43.676955Z",
     "shell.execute_reply.started": "2022-08-31T16:07:43.520737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get train/test dfs\n",
    "\n",
    "train_df = pd.read_csv('train.csv.zip', compression='zip')\n",
    "test_df = pd.read_csv('test.csv.zip', compression='zip')\n",
    "\n",
    "\n",
    "# Explore unique entries in categorical columns:\n",
    "\n",
    "cat_cols = ['product_code','attribute_0','attribute_1']\n",
    "    \n",
    "# Notice that 'product_code' unique entries among train and test dataset are completely different: I remove this columnn\n",
    "train_df = train_df.drop('product_code', axis = 1)\n",
    "test_df = test_df.drop('product_code', axis = 1)\n",
    "cat_cols.remove('product_code')\n",
    "\n",
    "# Rows are too many to be waisted.\n",
    "# I will drop attribute_1 column too:\n",
    "train_df = train_df.drop('attribute_1', axis = 1)\n",
    "test_df = test_df.drop('attribute_1', axis = 1)\n",
    "cat_cols.remove('attribute_1')\n",
    "\n",
    "\n",
    "#Explore amount of nans among all columns:\n",
    "\n",
    "col_nans_train_df = []\n",
    "for col in train_df.columns:\n",
    "    N_nan = train_df[col].isnull().sum()\n",
    "    col_nans_train_df.append(col)\n",
    "\n",
    "col_nans_test_df = []\n",
    "for col in test_df.columns:\n",
    "    N_nan = test_df[col].isnull().sum()\n",
    "    col_nans_test_df.append(col)\n",
    "\n",
    "\n",
    "# Get rid of the Nans:\n",
    "\n",
    "# Categorical columns (they all have Nans):\n",
    "train_df.loc[:,cat_cols] = train_df.loc[:,cat_cols].fillna(train_df.loc[:,cat_cols].mode().iloc[0])\n",
    "test_df.loc[:,cat_cols] = test_df.loc[:,cat_cols].fillna(test_df.loc[:,cat_cols].mode().iloc[0])\n",
    "    \n",
    "# Numerical columns with nans (I choose substitution with mean value):\n",
    "for CC in cat_cols:\n",
    "        col_nans_train_df.remove(CC)\n",
    "        col_nans_test_df.remove(CC)\n",
    "train_df.loc[:,col_nans_train_df] = train_df.loc[:,col_nans_train_df].\\\n",
    "                                    fillna(train_df.loc[:,col_nans_train_df].mean())\n",
    "test_df.loc[:,col_nans_test_df] = test_df.loc[:,col_nans_test_df].\\\n",
    "                                    fillna(test_df.loc[:,col_nans_test_df].mean())\n",
    "\n",
    "\n",
    "# Apply One-Hot encoder:\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_df[cat_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(test_df[cat_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_df.index\n",
    "OH_cols_test.index = test_df.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_train = train_df.drop(cat_cols, axis=1)\n",
    "num_test = test_df.drop(cat_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_train_df = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "OH_test_df = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Divide dataframes into X,y:\n",
    "\n",
    "# Full dataframes (for final training for submission)\n",
    "X_cols = OH_train_df.columns.drop('failure')\n",
    "X_train_all = OH_train_df.loc[:,X_cols]\n",
    "y_train_all = OH_train_df.loc[:,'failure']\n",
    "X_test_all = OH_test_df\n",
    "\n",
    "# Get partial train/test sets from train_df to explore different setup of models/parameters.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:07:55.043919Z",
     "iopub.status.busy": "2022-08-31T16:07:55.043630Z",
     "iopub.status.idle": "2022-08-31T16:10:31.232214Z",
     "shell.execute_reply": "2022-08-31T16:10:31.231078Z",
     "shell.execute_reply.started": "2022-08-31T16:07:55.043896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auc score of XGBClassifier with specific parameters values: \n",
      "n_estimators = 350.00  learning_rate = 0.01 --> auc = 0.584\n",
      "n_estimators = 350.00  learning_rate = 0.05 --> auc = 0.563\n",
      "n_estimators = 350.00  learning_rate = 0.10 --> auc = 0.549\n",
      "n_estimators = 350.00  learning_rate = 0.50 --> auc = 0.522\n",
      "n_estimators = 500.00  learning_rate = 0.01 --> auc = 0.581\n",
      "n_estimators = 500.00  learning_rate = 0.05 --> auc = 0.557\n",
      "n_estimators = 500.00  learning_rate = 0.10 --> auc = 0.542\n",
      "n_estimators = 500.00  learning_rate = 0.50 --> auc = 0.521\n",
      "n_estimators = 750.00  learning_rate = 0.01 --> auc = 0.578\n",
      "n_estimators = 750.00  learning_rate = 0.05 --> auc = 0.551\n",
      "n_estimators = 750.00  learning_rate = 0.10 --> auc = 0.537\n",
      "n_estimators = 750.00  learning_rate = 0.50 --> auc = 0.518\n"
     ]
    }
   ],
   "source": [
    "n_est_vals = [350,500,750]\n",
    "learning_rate_vals = [0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "print('\\nAuc score of XGBClassifier with specific parameters values: ')\n",
    "for n_est_val in n_est_vals:\n",
    "    for learning_rate_val in learning_rate_vals:\n",
    "        clf = XGBClassifier(n_estimators=n_est_val, learning_rate = learning_rate_val, eval_metric='auc')\n",
    "        clf.fit(X_train, y_train, verbose=False)\n",
    "        y_pred_clf = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        clf_fpr, clf_tpr, threshold = roc_curve(y_test, y_pred_clf)\n",
    "        auc_clf = roc_auc_score(y_test, y_pred_clf)\n",
    "        \n",
    "        print('n_estimators = {:.2f}  learning_rate = {:.2f} --> auc = {:.3f}'\\\n",
    "              .format(n_est_val, learning_rate_val, auc_clf))\n",
    "        \n",
    "# One-Hot encoder actually makes it worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier with n_estimators = 350.00  learning_rate = 0.01\n",
    "with Ordinal encoder\n",
    "\n",
    "Now let's train our model over the full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:26:21.007603Z",
     "iopub.status.busy": "2022-08-31T16:26:21.007283Z",
     "iopub.status.idle": "2022-08-31T16:26:21.170377Z",
     "shell.execute_reply": "2022-08-31T16:26:21.168857Z",
     "shell.execute_reply.started": "2022-08-31T16:26:21.007564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get train/test dfs\n",
    "\n",
    "train_df = pd.read_csv('train.csv.zip', compression='zip')\n",
    "test_df = pd.read_csv('test.csv.zip', compression='zip')\n",
    "\n",
    "\n",
    "# Explore unique entries in categorical columns:\n",
    "\n",
    "cat_cols = ['product_code','attribute_0','attribute_1']\n",
    "    \n",
    "# Notice that 'product_code' unique entries among train and test dataset are completely different: I remove this columnn\n",
    "train_df = train_df.drop('product_code', axis = 1)\n",
    "test_df = test_df.drop('product_code', axis = 1)\n",
    "cat_cols.remove('product_code')\n",
    "\n",
    "# Rows are too many to be waisted.\n",
    "# I will drop attribute_1 column too:\n",
    "train_df = train_df.drop('attribute_1', axis = 1)\n",
    "test_df = test_df.drop('attribute_1', axis = 1)\n",
    "cat_cols.remove('attribute_1')\n",
    "\n",
    "\n",
    "\n",
    "#Explore amount of nans among all columns:\n",
    "\n",
    "col_nans_train_df = []\n",
    "for col in train_df.columns:\n",
    "    N_nan = train_df[col].isnull().sum()\n",
    "    col_nans_train_df.append(col)\n",
    "\n",
    "col_nans_test_df = []\n",
    "for col in test_df.columns:\n",
    "    N_nan = test_df[col].isnull().sum()\n",
    "    col_nans_test_df.append(col)\n",
    "\n",
    "\n",
    "\n",
    "# Get rid of the Nans:\n",
    "\n",
    "# Categorical columns (they all have Nans):\n",
    "train_df.loc[:,cat_cols] = train_df.loc[:,cat_cols].fillna(train_df.loc[:,cat_cols].mode().iloc[0])\n",
    "test_df.loc[:,cat_cols] = test_df.loc[:,cat_cols].fillna(test_df.loc[:,cat_cols].mode().iloc[0])\n",
    "    \n",
    "# Numerical columns with nans (I choose substitution with mean value):\n",
    "for CC in cat_cols:\n",
    "        col_nans_train_df.remove(CC)\n",
    "        col_nans_test_df.remove(CC)\n",
    "train_df.loc[:,col_nans_train_df] = train_df.loc[:,col_nans_train_df].\\\n",
    "                                    fillna(train_df.loc[:,col_nans_train_df].mean())\n",
    "test_df.loc[:,col_nans_test_df] = test_df.loc[:,col_nans_test_df].\\\n",
    "                                    fillna(test_df.loc[:,col_nans_test_df].mean())\n",
    "\n",
    "# Apply encoder:\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "train_df.loc[:,cat_cols] = ordinal_encoder.fit_transform(train_df.loc[:,cat_cols])\n",
    "test_df.loc[:,cat_cols] = ordinal_encoder.transform(test_df.loc[:,cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T16:26:24.513859Z",
     "iopub.status.busy": "2022-08-31T16:26:24.513422Z",
     "iopub.status.idle": "2022-08-31T16:26:24.520930Z",
     "shell.execute_reply": "2022-08-31T16:26:24.520092Z",
     "shell.execute_reply.started": "2022-08-31T16:26:24.513833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Full dataframes (for final training for submission)\n",
    "X_cols = train_df.columns.drop('failure')\n",
    "X_train_all = train_df.loc[:,X_cols]\n",
    "y_train_all = train_df.loc[:,'failure']\n",
    "X_test_all = test_df\n",
    "\n",
    "# Fit model and get predictions\n",
    "clf = XGBClassifier(n_estimators=350, learning_rate = 0.01, eval_metric='auc')\n",
    "clf.fit(X_train_all, y_train_all, verbose=False)\n",
    "predictions = clf.predict_proba(X_test_all)[:, 1]\n",
    "\n",
    "# Save to output\n",
    "output = pd.DataFrame({'id': X_test_all['id'],\n",
    "                       'failure': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen model scored a ROC AUC value of about 0.60 when submitted to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
